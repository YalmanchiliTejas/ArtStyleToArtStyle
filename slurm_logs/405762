Using cuda
Using 2 GPUs with DataParallel
[Epoch 1/10] [Iter 50/125] D: 7.0980, G: 23.8194, loss_g_adversial: 8.1479, loss_cycle: 1.0634, loss_identity: 1.0075, loss_d_x: 2.4400, loss_d_y: 4.6580
[Epoch 1/10] [Iter 100/125] D: 4.1733, G: 13.8441, loss_g_adversial: 4.7914, loss_cycle: 0.6292, loss_identity: 0.5521, loss_d_x: 0.3566, loss_d_y: 3.8167
[Epoch 2/10] [Iter 50/125] D: 0.5653, G: 11.8021, loss_g_adversial: 0.7000, loss_cycle: 0.7738, loss_identity: 0.6729, loss_d_x: 0.3134, loss_d_y: 0.2519
[Epoch 2/10] [Iter 100/125] D: 35.6749, G: 46.8396, loss_g_adversial: 32.7488, loss_cycle: 0.9643, loss_identity: 0.8896, loss_d_x: 0.4541, loss_d_y: 35.2209
[Epoch 3/10] [Iter 50/125] D: 0.5399, G: 20.7413, loss_g_adversial: 1.5891, loss_cycle: 1.2898, loss_identity: 1.2507, loss_d_x: 0.4250, loss_d_y: 0.1149
[Epoch 3/10] [Iter 100/125] D: 0.4706, G: 18.4591, loss_g_adversial: 1.8198, loss_cycle: 1.1157, loss_identity: 1.0965, loss_d_x: 0.4321, loss_d_y: 0.0385
[Epoch 4/10] [Iter 50/125] D: 3376.0164, G: 5161.0771, loss_g_adversial: 5131.3198, loss_cycle: 1.9689, loss_identity: 2.0137, loss_d_x: 3375.9849, loss_d_y: 0.0315
[Epoch 4/10] [Iter 100/125] D: 0.6040, G: 30.4012, loss_g_adversial: 1.1984, loss_cycle: 1.9258, loss_identity: 1.9889, loss_d_x: 0.5619, loss_d_y: 0.0422
[Epoch 5/10] [Iter 50/125] D: 0.2585, G: 29.8849, loss_g_adversial: 1.6651, loss_cycle: 1.8610, loss_identity: 1.9220, loss_d_x: 0.2395, loss_d_y: 0.0189
[Epoch 5/10] [Iter 100/125] D: 0.3103, G: 22.2112, loss_g_adversial: 1.2767, loss_cycle: 1.3891, loss_identity: 1.4087, loss_d_x: 0.1466, loss_d_y: 0.1637
The checkpoint is saved to this pathcheckpoints/cezanne2photo_baseline/checkpoint_epoch_0005.pt
Traceback (most recent call last):
  File "/home/venkat97/cs593-cvd/ArtStyleToArtStyle/train_baseline.py", line 417, in <module>
    main()
  File "/home/venkat97/cs593-cvd/ArtStyleToArtStyle/train_baseline.py", line 413, in main
    train(args)
  File "/home/venkat97/cs593-cvd/ArtStyleToArtStyle/train_baseline.py", line 257, in train
    save_samples(model, device, sample_batch, output = args.sample_dir, epoch=epoch,max_num=3)
  File "/home/venkat97/.conda/envs/cent7/2024.02-py311/CS587/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/venkat97/cs593-cvd/ArtStyleToArtStyle/train_baseline.py", line 126, in save_samples
    real_x, real_y, fake_x , fake_y, rec_x , rec_y = model(real_x, real_y)
                                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/venkat97/.conda/envs/cent7/2024.02-py311/CS587/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/venkat97/.conda/envs/cent7/2024.02-py311/CS587/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/venkat97/.conda/envs/cent7/2024.02-py311/CS587/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py", line 184, in forward
    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/venkat97/.conda/envs/cent7/2024.02-py311/CS587/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py", line 189, in replicate
    return replicate(module, device_ids, not torch.is_grad_enabled())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/venkat97/.conda/envs/cent7/2024.02-py311/CS587/lib/python3.11/site-packages/torch/nn/parallel/replicate.py", line 110, in replicate
    param_copies = _broadcast_coalesced_reshape(params, devices, detach)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/venkat97/.conda/envs/cent7/2024.02-py311/CS587/lib/python3.11/site-packages/torch/nn/parallel/replicate.py", line 79, in _broadcast_coalesced_reshape
    return comm.broadcast_coalesced(tensors, devices)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/venkat97/.conda/envs/cent7/2024.02-py311/CS587/lib/python3.11/site-packages/torch/nn/parallel/comm.py", line 57, in broadcast_coalesced
    return torch._C._broadcast_coalesced(tensors, devices, buffer_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: NCCL Error 5: invalid usage (run with NCCL_DEBUG=WARN for details)
